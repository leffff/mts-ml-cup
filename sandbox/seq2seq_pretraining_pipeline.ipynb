{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c646f0c",
   "metadata": {},
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88993512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179dfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import polars as pl\n",
    "import scipy\n",
    "import implicit\n",
    "import bisect\n",
    "import sklearn.metrics as m\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from transformers import get_constant_schedule, get_cosine_schedule_with_warmup\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08884ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import modules\n",
    "import fe_modules\n",
    "import seq2seq_modules\n",
    "\n",
    "importlib.reload(modules)\n",
    "importlib.reload(fe_modules)\n",
    "importlib.reload(seq2seq_modules)\n",
    "\n",
    "from modules.memory_utils import pandas_reduce_mem_usage, pandas_string_to_cat\n",
    "from seq2seq_modules.data import CoLESDataset\n",
    "from seq2seq_modules.models import LSTMModel\n",
    "from seq2seq_modules.weight_initialization import weights_init_uniform_rule, weights_init_xavier\n",
    "from seq2seq_modules.loops import cross_validation, single_model_training\n",
    "from seq2seq_modules.utils import age_bucket\n",
    "from seq2seq_modules.metrics import AGE_METRIC\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47431eb8",
   "metadata": {},
   "source": [
    "## Read and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17c3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = './data/'\n",
    "SPLIT_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac71fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"user_id\"]\n",
    "\n",
    "cat_features = [\n",
    "    \"region_name\",\n",
    "    \"city_name\",\n",
    "    \"cpe_manufacturer_name\",\n",
    "    \"cpe_model_name\",\n",
    "    \"url_host\",\n",
    "    \"cpe_type_cd\",\n",
    "    \"cpe_model_os_type\",\n",
    "    \"part_of_day\",\n",
    "    \"domain\",\n",
    "    \"capital_marker\"\n",
    "]\n",
    "\n",
    "continous_features = [\n",
    "    \"request_cnt\",\n",
    "    \"price\",\n",
    "    \"timestamp\",\n",
    "    \"relative_timestamp\",\n",
    "    \"geo_lat\",\n",
    "    \"geo_lon\",\n",
    "    \"population\",\n",
    "    \"timezone\",\n",
    "    \"dist_to_Moscow\",\n",
    "    \"dist_to_SaintP\",\n",
    "    \"dist_to_Novosibirsk\",\n",
    "    \"dist_to_Ekaterinburg\",\n",
    "    \"dist_to_Vladivostok\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd60063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 26346.12 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff861504e8849f8a9148453e0508147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 26346.12 MB\n",
      "Decreased by 0.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cpe_manufacturer_name</th>\n",
       "      <th>cpe_model_name</th>\n",
       "      <th>url_host</th>\n",
       "      <th>cpe_type_cd</th>\n",
       "      <th>cpe_model_os_type</th>\n",
       "      <th>price</th>\n",
       "      <th>part_of_day</th>\n",
       "      <th>request_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>timezone</th>\n",
       "      <th>geo_lat</th>\n",
       "      <th>geo_lon</th>\n",
       "      <th>population</th>\n",
       "      <th>dist_to_Moscow</th>\n",
       "      <th>dist_to_SaintP</th>\n",
       "      <th>dist_to_Novosibirsk</th>\n",
       "      <th>dist_to_Ekaterinburg</th>\n",
       "      <th>dist_to_Vladivostok</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>5788</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20368.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>45.040161</td>\n",
       "      <td>38.975964</td>\n",
       "      <td>744933</td>\n",
       "      <td>1195.817871</td>\n",
       "      <td>1755.62085</td>\n",
       "      <td>3275.137451</td>\n",
       "      <td>1992.558472</td>\n",
       "      <td>6999.525391</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>12900</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20368.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>45.040161</td>\n",
       "      <td>38.975964</td>\n",
       "      <td>744933</td>\n",
       "      <td>1195.817871</td>\n",
       "      <td>1755.62085</td>\n",
       "      <td>3275.137451</td>\n",
       "      <td>1992.558472</td>\n",
       "      <td>6999.525391</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>17626</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20368.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>45.040161</td>\n",
       "      <td>38.975964</td>\n",
       "      <td>744933</td>\n",
       "      <td>1195.817871</td>\n",
       "      <td>1755.62085</td>\n",
       "      <td>3275.137451</td>\n",
       "      <td>1992.558472</td>\n",
       "      <td>6999.525391</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>59366</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20368.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>45.040161</td>\n",
       "      <td>38.975964</td>\n",
       "      <td>744933</td>\n",
       "      <td>1195.817871</td>\n",
       "      <td>1755.62085</td>\n",
       "      <td>3275.137451</td>\n",
       "      <td>1992.558472</td>\n",
       "      <td>6999.525391</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>59366</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20368.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>45.040161</td>\n",
       "      <td>38.975964</td>\n",
       "      <td>744933</td>\n",
       "      <td>1195.817871</td>\n",
       "      <td>1755.62085</td>\n",
       "      <td>3275.137451</td>\n",
       "      <td>1992.558472</td>\n",
       "      <td>6999.525391</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_name  city_name  cpe_manufacturer_name  cpe_model_name  url_host  \\\n",
       "0           21        409                      1             589      5788   \n",
       "1           21        409                      1             589     12900   \n",
       "2           21        409                      1             589     17626   \n",
       "3           21        409                      1             589     59366   \n",
       "4           21        409                      1             589     59366   \n",
       "\n",
       "   cpe_type_cd  cpe_model_os_type    price  part_of_day  request_cnt  ...  \\\n",
       "0            2                  1  20368.0            2            1  ...   \n",
       "1            2                  1  20368.0            2            1  ...   \n",
       "2            2                  1  20368.0            0            1  ...   \n",
       "3            2                  1  20368.0            0            1  ...   \n",
       "4            2                  1  20368.0            0            1  ...   \n",
       "\n",
       "   timezone    geo_lat    geo_lon  population  dist_to_Moscow  dist_to_SaintP  \\\n",
       "0         3  45.040161  38.975964      744933     1195.817871      1755.62085   \n",
       "1         3  45.040161  38.975964      744933     1195.817871      1755.62085   \n",
       "2         3  45.040161  38.975964      744933     1195.817871      1755.62085   \n",
       "3         3  45.040161  38.975964      744933     1195.817871      1755.62085   \n",
       "4         3  45.040161  38.975964      744933     1195.817871      1755.62085   \n",
       "\n",
       "   dist_to_Novosibirsk  dist_to_Ekaterinburg  dist_to_Vladivostok  domain  \n",
       "0          3275.137451           1992.558472          6999.525391     761  \n",
       "1          3275.137451           1992.558472          6999.525391     549  \n",
       "2          3275.137451           1992.558472          6999.525391     712  \n",
       "3          3275.137451           1992.558472          6999.525391     712  \n",
       "4          3275.137451           1992.558472          6999.525391     712  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas_reduce_mem_usage(\n",
    "    pd.read_parquet(\"../seq2seq_data/stages/stage_2.parquet.gzip\")\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec1d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbceba074144df0a4f39eb292679470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/328879856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seq2seq_modules.data.CoLESDataset at 0x7f211d25bcd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CoLESDataset(\n",
    "         df,\n",
    "         agg_column=\"user_id\", \n",
    "         time_column=\"timestamp\",\n",
    "         cat_features=cat_features,\n",
    "         cont_features=continous_features,\n",
    "         num_splits=5,\n",
    "         max_len=1024,\n",
    "         padding_side=\"left\",\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9dbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "[dataset[i] for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6acaecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 22.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 478297.82it/s]\n"
     ]
    }
   ],
   "source": [
    "cat_feature_indexes = []\n",
    "cont_feature_indexes = []\n",
    "vocab_sizes = {}\n",
    "\n",
    "for i in tqdm(range(len(cat_features))):\n",
    "    cat_feature_indexes.append(i)\n",
    "    vocab_sizes[i] = int(df[cat_features[i]].max() + 1)\n",
    "\n",
    "for i in tqdm(range(len(continous_features))):\n",
    "    cont_feature_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf09ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      0,      0,  ..., 415301, 415301, 415301])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.tensor(dataset.targets)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33687ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(\n",
    "        cat_feature_indexes=cat_feature_indexes,\n",
    "        vocab_sizes=vocab_sizes,\n",
    "        cont_feature_indexes=cont_feature_indexes,\n",
    "        encoder_hidden_dim=16,\n",
    "        hidden_dim=256,\n",
    "        output_dim=7,\n",
    ")\n",
    "\n",
    "weights_init_xavier(model)\n",
    "\n",
    "loss = ArcFaceLoss(num_classes=targets.unique().shape[0], embedding_size=256)\n",
    "\n",
    "metric = AGE_METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f593ca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a0bcddb4f84bfaa8ae3e3cb1e1b8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2072902 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x7 and 256x402091)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msingle_model_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_cosine_schedule_with_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m69\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/seq2seq_modules/loops.py:262\u001b[0m, in \u001b[0;36msingle_model_training\u001b[0;34m(model, dataset, loss_function, metric_func, optimizer, get_scheduler, pretraining, device, random_state, shuffle, epochs, lr, batch_size, start_epoch)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start_epoch:\n\u001b[0;32m--> 262\u001b[0m         train_metrics, embeddings, logits, targets \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpass_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpretraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;66;03m# save_model(model, save_folder, f\"epoch_{epoch_i}\")\u001b[39;00m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch_i)\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/seq2seq_modules/loops.py:41\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_function, optimizer, scheduler, device, metric_func, pass_logits)\u001b[0m\n\u001b[1;32m     38\u001b[0m targets\u001b[38;5;241m.\u001b[39mappend(batch_target\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pass_logits:\n\u001b[0;32m---> 41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(batch_embeddings\u001b[38;5;241m.\u001b[39mdouble(), batch_target)\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/pytorch_metric_learning/losses/base_metric_loss_function.py:34\u001b[0m, in \u001b[0;36mBaseMetricLossFunction.forward\u001b[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m     labels \u001b[38;5;241m=\u001b[39m c_f\u001b[38;5;241m.\u001b[39mto_device(labels, embeddings)\n\u001b[1;32m     33\u001b[0m ref_emb, ref_labels \u001b[38;5;241m=\u001b[39m c_f\u001b[38;5;241m.\u001b[39mset_ref_emb(embeddings, labels, ref_emb, ref_labels)\n\u001b[0;32m---> 34\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embedding_regularization_to_loss_dict(loss_dict, embeddings)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer(loss_dict, embeddings, labels)\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/pytorch_metric_learning/losses/large_margin_softmax_loss.py:108\u001b[0m, in \u001b[0;36mLargeMarginSoftmaxLoss.compute_loss\u001b[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m    106\u001b[0m miner_weights \u001b[38;5;241m=\u001b[39m lmu\u001b[38;5;241m.\u001b[39mconvert_to_weights(indices_tuple, labels, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    107\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_target_mask(embeddings, labels)\n\u001b[0;32m--> 108\u001b[0m cosine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m cosine_of_target_classes \u001b[38;5;241m=\u001b[39m cosine[mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    110\u001b[0m modified_cosine_of_target_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodify_cosine_of_target_classes(\n\u001b[1;32m    111\u001b[0m     cosine_of_target_classes\n\u001b[1;32m    112\u001b[0m )\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/pytorch_metric_learning/losses/large_margin_softmax_loss.py:57\u001b[0m, in \u001b[0;36mLargeMarginSoftmaxLoss.get_cosine\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cosine\u001b[39m(\u001b[38;5;28mself\u001b[39m, embeddings):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/pytorch_metric_learning/distances/base_distance.py:38\u001b[0m, in \u001b[0;36mBaseDistance.forward\u001b[0;34m(self, query_emb, ref_emb)\u001b[0m\n\u001b[1;32m     34\u001b[0m     ref_emb_normalized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_normalize(ref_emb)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_default_stats(\n\u001b[1;32m     36\u001b[0m     query_emb, ref_emb, query_emb_normalized, ref_emb_normalized\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_emb_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_emb_normalized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpower \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     40\u001b[0m     mat \u001b[38;5;241m=\u001b[39m mat\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpower\n",
      "File \u001b[0;32m~/PycharmProjects/mts-ml-cup/venv/lib/python3.10/site-packages/pytorch_metric_learning/distances/dot_product_similarity.py:12\u001b[0m, in \u001b[0;36mDotProductSimilarity.compute_mat\u001b[0;34m(self, query_emb, ref_emb)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_mat\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_emb, ref_emb):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_emb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x7 and 256x402091)"
     ]
    }
   ],
   "source": [
    "single_model_training(\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        loss_function=loss,\n",
    "        metric_func=metric,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        get_scheduler=get_cosine_schedule_with_warmup,\n",
    "        pretraining=True,\n",
    "        device=torch.device(\"cuda\"),\n",
    "        random_state=69,\n",
    "        shuffle=True,\n",
    "        epochs=10,\n",
    "        lr=1e-5,\n",
    "        batch_size=32,\n",
    "        start_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd359d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66332863, 66332863, 328849595)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.cat_sequences), len(dataset.cont_sequences), len(dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7f42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
